
Data generated by network sensors:

Examples:

	NetFlow sensors on a router 

	Sensors that collect traffic using packet capture, most notably tcpdump

Packet and Frame Formats

	On almost any modern system, tcpdump will be capturing IP over Ethernet, meaning that the data actually captured by 'libcap' consists of Ethernet frames containing over 80 unique protocols, on any operational network the overwhelming majority of traffic will originate from just 3 of these: TCP(protocol 6), UDP(protocol 17), and ICMP(protocol 1).

	While TCP, UDP, and ICMP make up the overwhelming majority of IP traffic, a number of other protocols may appear in networks, in particular if VPNs are used. 

	The Internet Assigned Numbers Authority (IANA) has a complete list of IP suite protocols. 

	Full packet capture is often impractical. its too big and redundant as hell. 

	There are three major mechanisms for filtering or limiting packet capture data:

		The use of rolling buffers to keep a timed subsample

		Manipulating the snap length to capture only a fixed-size packet (such as headers) 

		Filtering traffic using Berkeley Packet Filter (BPF) or other filtering rules. 

	Each approach is an analytics trade-off that provides different benefits and disadvantages.

	While tcpdump is the oldest and most common packet capture tool , there are many alternatives.
		In the purely software domain, Googl'e Stenographer project is a high-performance capture solution, and AOL's Moloch combines packet capture and analysis. 

		There are also a number of hardware-based capture tools that use optimized NICs to capture at higher line speeds. 

	Rolling Buffers:

		A rolling buffer is a location in memory where data is dumped cyclically: information is dropped linearly, and when the buffer is filled up, data is duimped at the beginning of the buffer, and the process repeats. 

		Implementing a rolling buffer in tcpdump:
			rolling_buffer_tcpdump.sh

		Rolling buffers implement a time horizon on traffic analysis: data is available only as long as it's in the buffer. For that reason, working with smaller file sizes is recommended, because when you find something aberrant, it needs to be pulled out of the buffers quickly. 

	Limiting the Data captured from each packet:

		