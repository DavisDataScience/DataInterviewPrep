1. Why is Cross Validation important?

	In ML it is important to asses how a model learned from training data can be generalized on a new unseen data set. In particular a problem of overfitting is observed when a model make good predictions on the training data but has poor performance on unknown data. 

	Cross-val is used a lot for reducing the overfitting risk. It splits the training data into two parts: One is the proper training set, while the other is the validation set which is used to check overfitting and find the best partition according to some evaluation metric. There are three commonly used options:
		1. K-fold cross-val: Data is divided into a train and a validation set for k-times (called folds) and the minimizing combination is then selected. 
		2. Leave one out validation: very similar to k-fold but the folds contain a single point
		3. Stratified k-fold cross-val: the folds are selected so that the mean is approximately the same in all the folds
	Code:
		import numpy as np
		from sklearn import cross_validation
		from sklearn import datasets
		from sklearn import svm
		diabets = datasets.load_diabetes()
		X_train, X_test, y_train, y_test = cross_validation.train_test_split(diabets.data, diabets.target, test_size=0.2, random_state=0)
		print(X_train.shape, y_train.shape)
		print(X_test.shape, y_test.shape)
		clf = svm.SVC(kernel='linear', C=1)
		scores = cross_validation.cross_val_score(clf, diabets.data, diabets.target, cv=4) # 4-folds
		print(scores)
		print("Mean: {}. \nScore: {}".format(scores.mean(), scores.std()))		from sklearn import cross_validation

2. Why is Grid Search important?
	
	In ML it is important to asses which is the best configuration of hyperparamters for a learning algorithm. As usual, the goal is to optimize some well-defined evaluation metrics. Let us dig into those aspects in more detail. First lets clarify that learning algorithms learn parameters in order to create models based on input data. Second let us clarify that hyperparameters are then selected to ensure that a given model does not overfit its training data.

	Grid search is an exhaustive search procedure that explores a space of manually defined hyperparameters by testing all possible configurations and selecting the most effective one. 

	The code below runs a cross-val on a KNN classifier with 10 folds. The eval metric is accuracy. Then it performs a grid search on a parameter space defined in terms of number of neighbors to be considered(from 1 to 10), in terms of weights (uniform or distance-based) and in terms of Power parameter for the Minkowski metric (when p=1, this is equivalent to the manhattan distance (l1), or a euclidean distance (l2) for p=2).

	The whole grid consists of a space of 10(neighbors) * 2(weights) * 2(distances) points which are exhaustively searched by the algorithm via GridSearchCV. The best configuration is then returned.

	Code:
		
		from sklearn.cross_validation import cross_val_score
		from sklearn.neighbors import KNeighborsClassifier
		from sklearn.grid_search import GridSearchCV
		from sklearn import datasets
		import numpy as np

		# load toy dataset
		boston = datasets.load_boston()

		X, y = boston.data, boston.target
		yint = y[:].astype(int)

		# grid = 20 x 2 x 3
		classifier = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='minkowski', p=2)

		grid = {'n_neighbors:' range(1,11), 'weights': ['uniform', 'distance'], 'p': [1,2]}

		print('baseline: {}'.format(np.mean(cross_val_score(classifier, X, yint, cv=10, scoring='accuracy', n_jobs=1))) # 10 fold accuracy

		search = GridSearchCV(estimator=classifier, param_grid=grid, scoring='accuracy', n_jobs=1m refit=True, cv=10)

		search.fit(X, yint) # grid search across paramters for classifier

		print("Best Parametes: {}".format(search.best_params_))
		print("Accuracy: {}".format(best_score_))

4. How do we deal with categorical features? And what is one-hot encoding?

	At times, datasets contain categorical features, such as Nationality: British, French, etc. A one-hot encoder maps a column of categories int a column of sparse binary vectors (1 or 0) with at most one single one-value per row that indicates the input category index. One-hot encoding is very useful for dealing with categorical features. 

	Many learning algorithms learn one single weights per feature. For instance, a linear classifier has the form wx + b > 0 and will learn one single weight for the feature "Nationality". Sometimes this is a limit because we might want to differentiate situations where people have more than one nationality (French and US might be different from Canadian and US). One-hot encoding will naturally capture these types of interactions in the data by blowing up the feature space where each choice of nationality gets its own sparse representation.

5. What are generalized linear models and what is an R Formula?
	
	Generalized linear models unify various statistical models, such as linear and logistic regression, through the specification of a model family and link function. For instance, one formula could be y~f0+f1 meaning the prediction for y is linearly modelled as a function of the features f0 and f1.

	More complex examples can be built using R operators like inclusion (+), exclusion (-), inclusion all (.), and others.

6. What are Decision Trees?

	A class of machine learning algorithms where the learned model is represented by a tree. Each node represents a choice associated to one input feature and the edge departing from that node represents the potentional outcomes for the choice. 

	Tree models where the target variable can take a finite set of values are called classification trees, while tree models where the target variable can take continuous variabes are called regression trees. 

	How does one define the 'best' choice?

	Gini Impurity: The sum of the probabilities of each item being chosen, multiplied by the probability of mistaken categorization. 

	Information gain: The difference between the entropy computed before and after performing a split on a particular feature, where the entropy of a random variable X is H(X) =- sum(prob(Xi)* logProb(Xi))

	Variance reduction: the difference between the variance computed before and after performing a split on a particular feature

	The process finds the best decision for each node, and recursively does so for the span of the tree children. 

	Pros:

		Easy to understand

		categorical and continuous data input

		applicable to large datasets with reasonable robustness for outliers

	Cons:

		Learning an optimal decision tree is an NP-complete problem, so the construction is based on heuristics which are frequently making locally-optimal decisions at each node. This decision cannot be reverted (except with random forest, gradient boosting)

		Can overfit training data and frequently do not generalize well on new unseen data. Pruning and randomization techiques minimize the impact of this problem. 

7. What are Ensembles? 

	A class of methods that generate multiple hypotheses using the same base learner. The key intuition is that the combination of multiple hypotheses learned from the data can indeed generate a better prediction than the one generated with a single hypothesis. There are multiple ways to combine base models...

		Bagging: trains each model in the ensemble using a randomly drawn subset of the training set. Then each model in the ensemble votes with equal weight

		Boosting: incrementally builds an ensemble by training each new model instance in such a way that the training instances of that previously misclassified models are thus emphasized. 

		Stacking/Blending: combines predictions built with multiple different learning techniques. The combination is also learned with a special ad-hoc learned model. 

8. What is a gradient boosted tree?

	



	

